{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# from models.research.object_detection.utils import label_map_util\n",
    "# from models.research.object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing basketball_net ssd trained on COCO\n",
    "\n",
    "# category_index = label_map_util.create_category_index_from_labelmap('basketball_training/label_map.pbtxt', \n",
    "#                                                                     use_display_name=True)\n",
    "\n",
    "def load_graph(frozen_graph_filename):\n",
    "    # We load the protobuf file from the disk and parse it to retrieve the \n",
    "    # unserialized graph_def\n",
    "    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    # Then, we import the graph_def into a new Graph and return it \n",
    "    with tf.Graph().as_default() as graph:\n",
    "        # The name var will prefix every op/nodes in your graph\n",
    "        # Since we load everything in a new graph, this is not needed\n",
    "        tf.import_graph_def(graph_def, name='')\n",
    "    return graph\n",
    "\n",
    "\n",
    "graph = load_graph('basketball_training/inceptionv2-8086/frozen_inference_graph.pb')\n",
    "sess = tf.Session(graph=graph)\n",
    "# for op in graph.get_operations(): \n",
    "#     print(op.name, op.outputs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawBoxes(image_np, coordinates):\n",
    "    \n",
    "    # ymin, xmin, ymax, xmax\n",
    "    # h, w, rgb\n",
    "    ymin = int(coordinates[0]*image_np.shape[0])\n",
    "    ymax = int(coordinates[2]*image_np.shape[0])\n",
    "    xmin = int(coordinates[1]*image_np.shape[1])\n",
    "    xmax = int(coordinates[3]*image_np.shape[1])\n",
    "    \n",
    "    colour = np.array([0, 255, 0], dtype = np.uint8)\n",
    "    \n",
    "    line_width = 3\n",
    "    \n",
    "    image_np[ymin:ymax, xmax-line_width:xmax+line_width] = colour\n",
    "    image_np[ymin:ymax, xmin-line_width:xmin+line_width] = colour\n",
    "    image_np[ymin-line_width:ymin+line_width, xmin:xmax] = colour\n",
    "    image_np[ymax-line_width:ymax+line_width, xmin:xmax] = colour\n",
    "    \n",
    "    \n",
    "def showInference(image_np):\n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    image_tensor = graph.get_tensor_by_name('image_tensor:0')\n",
    "    # Each box represents a part of the image where a particular object was detected.\n",
    "    boxes = graph.get_tensor_by_name('detection_boxes:0')\n",
    "    # Each score represent how level of confidence for each of the objects.\n",
    "    # Score is shown on the result image, together with the class label.\n",
    "    scores = graph.get_tensor_by_name('detection_scores:0')\n",
    "    classes = graph.get_tensor_by_name('detection_classes:0')\n",
    "    num_detections = graph.get_tensor_by_name('num_detections:0')\n",
    "    \n",
    "    # Actual detection.\n",
    "    (boxes, scores, classes, num_detections) = sess.run(\n",
    "      [boxes, scores, classes, num_detections],\n",
    "      feed_dict={image_tensor: image_np_expanded})\n",
    "    \n",
    "    # Data to send via serial\n",
    "    box_data = np.squeeze(boxes)[0]\n",
    "    \n",
    "    center = None\n",
    "    confidence = None\n",
    "    if np.prod(box_data):\n",
    "        ymin, xmin, ymax, xmax = box_data\n",
    "        \n",
    "        # Relative Frame Coordinates\n",
    "        center = [image_np.shape[1]*ymin, image_np.shape[1]*ymax, image_np.shape[0]*xmin, image_np.shape[0]*xmax]\n",
    "\n",
    "        confidence = np.squeeze(scores)[0]\n",
    "        drawBoxes(image_np, box_data)\n",
    "\n",
    "    # Visualization of the results of a detection.\n",
    "#     vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "#       image_np,\n",
    "#       np.squeeze(boxes),\n",
    "#       np.squeeze(classes).astype(np.int32),\n",
    "#       np.squeeze(scores),\n",
    "#       category_index,\n",
    "#       use_normalized_coordinates=True,\n",
    "#       line_thickness=8)\n",
    "    \n",
    "    return center, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue, threading\n",
    "\n",
    "# bufferless VideoCapture\n",
    "class VideoCapture:\n",
    "  def __init__(self, name, width, height):\n",
    "    self.cap = cv2.VideoCapture(name)\n",
    "    self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "    self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "    self.width = width\n",
    "    self.height = height\n",
    "    self.q = queue.Queue()\n",
    "    self.read_lock = threading.Lock()\n",
    "    t = threading.Thread(target=self._reader)\n",
    "    t.daemon = True\n",
    "    t.start()\n",
    "\n",
    "  # read frames as soon as they are available, keeping only most recent one\n",
    "  def _reader(self):\n",
    "    while True:\n",
    "      ret, frame = self.cap.read()\n",
    "      if not ret:\n",
    "        break\n",
    "      if not self.q.empty():\n",
    "        try:\n",
    "          self.q.get_nowait()   # discard previous (unprocessed) frame\n",
    "        except queue.Empty:\n",
    "          pass\n",
    "      self.q.put(frame)\n",
    "        \n",
    "  def getWidth(self):\n",
    "    return 1280\n",
    "\n",
    "  def getHeight(self):\n",
    "    return 720\n",
    "\n",
    "  def isOpened(self):\n",
    "    return self.cap.isOpened()\n",
    "\n",
    "  def read(self):\n",
    "    return self.q.get()\n",
    "\n",
    "  def release(self):\n",
    "    self.cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kalman Filtering\n",
    "\n",
    "# Update prior beliefs as to where ball must have been subject to movement\n",
    "def update(mean1, var1, mean2, var2):\n",
    "    new_mean = []\n",
    "    for i in range(len(mean1)):\n",
    "        new_mean.append((mean1[i] * var2 + mean2[i] * var1) / (var1 + var2))\n",
    "    new_var = 1 / ((1 / var1) + (1 / var2))\n",
    "    \n",
    "    return new_mean, new_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280 720\n"
     ]
    }
   ],
   "source": [
    "# Video Capture\n",
    "\n",
    "cap = VideoCapture(1, 1280, 720)\n",
    "w = cap.getWidth()\n",
    "h = cap.getHeight()\n",
    "\n",
    "print(w,h)\n",
    "\n",
    "# Crop region is always in absolute coordinates\n",
    "\n",
    "orig_center = [h//2 - 300, h//2 + 300, w//2 - 300, w//2 + 300]\n",
    "crop_region = orig_center[:]\n",
    "prev_mean = orig_center[:]\n",
    "prev_var = 0.5\n",
    "\n",
    "while cap.isOpened():\n",
    "    image_np = cap.read()\n",
    "    image_np = image_np[crop_region[0]:crop_region[1], crop_region[2]:crop_region[3]]\n",
    "    \n",
    "    # Padding is a function of the current crop size\n",
    "    curr_mean, curr_var = showInference(image_np)\n",
    "    \n",
    "    if curr_mean and curr_var >= 0.6:\n",
    "        # Update prev_mean \n",
    "        #prev_mean, prev_var = update(curr_mean, curr_var, prev_mean, prev_var)\n",
    "        prev_mean, prev_var = curr_mean, curr_var # Ignore bayesian inference for now\n",
    "        \n",
    "        temp = crop_region\n",
    "        speed_ratio = 0.6\n",
    "        \n",
    "        # Shift Right\n",
    "        crop_region[2] += speed_ratio*(prev_mean[3])\n",
    "        crop_region[3] += speed_ratio*(prev_mean[3])\n",
    "        \n",
    "        # Shift Left\n",
    "        crop_region[2] -= speed_ratio*(temp[3] - temp[2] - prev_mean[2])\n",
    "        crop_region[3] -= speed_ratio*(temp[3] - temp[2] - prev_mean[2])\n",
    "        \n",
    "        # Shift Up\n",
    "        crop_region[0] -= speed_ratio*(temp[1] - temp[0] - prev_mean[0])\n",
    "        crop_region[1] -= speed_ratio*(temp[1] - temp[0] - prev_mean[0])\n",
    "        \n",
    "        # Shift Down\n",
    "        crop_region[0] += speed_ratio*(prev_mean[1])\n",
    "        crop_region[1] += speed_ratio*(prev_mean[1])\n",
    "        \n",
    "        # Zooming In and Out\n",
    "        ratioY = (prev_mean[1] - prev_mean[0]) / (crop_region[1] - crop_region[0])\n",
    "        ratioX = (prev_mean[3] - prev_mean[2]) / (crop_region[3] - crop_region[2])\n",
    "        \n",
    "        max_ratio = max(ratioY, ratioX)\n",
    "        threshold = 0.174\n",
    "        zoom_fact = 500\n",
    "    \n",
    "        crop_region[0] -= zoom_fact*(max_ratio - threshold)\n",
    "        crop_region[1] += zoom_fact*(max_ratio - threshold)\n",
    "        crop_region[2] -= zoom_fact*(max_ratio - threshold)\n",
    "        crop_region[3] += zoom_fact*(max_ratio - threshold)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        crop_region[0] -= 10\n",
    "        crop_region[1] += 10\n",
    "        crop_region[2] -= 10\n",
    "        crop_region[3] += 10\n",
    "\n",
    "    # Bounding\n",
    "    if crop_region[0] < 0:\n",
    "#             crop_region[1] -= crop_region[0]\n",
    "        crop_region[1] = min(crop_region[1] - crop_region[0], cap.getHeight())\n",
    "        crop_region[0] = 0\n",
    "    if crop_region[1] > cap.getHeight():\n",
    "#             crop_region[0] -= crop_region[1] - cap.getHeight()\n",
    "        crop_region[0] = max(crop_region[0] - crop_region[1] - cap.getHeight(), 0)\n",
    "        crop_region[1] = cap.getHeight()\n",
    "    if crop_region[2] < 0:\n",
    "#             crop_region[3] -= crop_region[2]\n",
    "        crop_region[3] = min(crop_region[3] - crop_region[2], cap.getWidth())\n",
    "        crop_region[2] = 0\n",
    "    if crop_region[3] > cap.getWidth():\n",
    "#             crop_region[2] -= crop_region[3] - cap.getWidth()\n",
    "        crop_region[2] = max(crop_region[2] - crop_region[3] - cap.getWidth(), 0)\n",
    "        crop_region[3] = cap.getWidth()\n",
    "\n",
    "    # Square Check\n",
    "    crop_width = crop_region[3] - crop_region[2]\n",
    "    crop_height = crop_region[1] - crop_region[0]\n",
    "\n",
    "    if crop_width > crop_height: # Wide\n",
    "        diff = crop_width - crop_height\n",
    "        crop_region[3] -= diff / 2\n",
    "        crop_region[2] += diff / 2\n",
    "    else:\n",
    "        diff = crop_height - crop_width\n",
    "        crop_region[0] += diff / 2\n",
    "        crop_region[1] -= diff / 2\n",
    "\n",
    "    crop_region[0] = int(crop_region[0])\n",
    "    crop_region[1] = int(crop_region[1])\n",
    "    crop_region[2] = int(crop_region[2])\n",
    "    crop_region[3] = int(crop_region[3])\n",
    "    cv2.imshow('object detection', cv2.resize(image_np, (480, 480)))\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    \n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "showInference() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-044f50c65b4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframe_count\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mshowInference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m480\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m480\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m480\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m480\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mframe_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: showInference() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# Captured Video processing - android\n",
    "\n",
    "cap = cv2.VideoCapture('tests/sanjay.mp4')\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "frame_count = 0\n",
    "while True:\n",
    "    _, image_np = cap.read()\n",
    "    \n",
    "    image_np = image_np[h//2 - 480:h//2 + 480, w//2 - 480:w//2 + 480]\n",
    "    #image_np = image_np[h//2 - 300:h//2 + 300, w//2 - 300:w//2 + 300]\n",
    "    \n",
    "    if not (frame_count % 1):\n",
    "        showInference(image_np, [h//2 - 480, h//2 + 480, w//2 - 480,w//2 + 480])\n",
    "        \n",
    "    frame_count += 1\n",
    "    cv2.imshow('object detection', image_np)\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('tests/sports_balls.jpg')\n",
    "resized_img = cv2.resize(img, (640,640), interpolation = cv2.INTER_AREA) \n",
    "\n",
    "image_np = np.asarray(resized_img)\n",
    "image_bgr = np.flip(image_np, axis=2)\n",
    "\n",
    "showInference(image_bgr)\n",
    "\n",
    "display(Image.fromarray(image_bgr))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional CV - Pretty bad\n",
    "from PIL import Image\n",
    "\n",
    "img = cv2.imread('tests/rodman2.jpg')\n",
    "\n",
    "# convert to HSV space\n",
    "im_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "# take only the orange, highly saturated, and bright parts\n",
    "im_hsv = cv2.inRange(im_hsv, (7,180,180), (11,255,255))\n",
    "\n",
    "# To show the detected orange parts:\n",
    "im_orange = img.copy()\n",
    "im_orange[im_hsv==0] = 0\n",
    "# cv2.imshow('im_orange',im_orange)\n",
    "\n",
    "# Perform opening to remove smaller elements\n",
    "element = np.ones((5,5)).astype(np.uint8)\n",
    "im_hsv = cv2.erode(im_hsv, element)\n",
    "im_hsv = cv2.dilate(im_hsv, element)\n",
    "\n",
    "points = np.dstack(np.where(im_hsv>0)).astype(np.float32)\n",
    "# fit a bounding circle to the orange points\n",
    "center, radius = cv2.minEnclosingCircle(points)\n",
    "# draw this circle\n",
    "cv2.circle(img, (int(center[1]), int(center[0])), int(radius), (255,0,0), thickness=6)\n",
    "\n",
    "out = np.vstack([im_orange,img])\n",
    "cv2.imwrite('tests/out.png',out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image cropping - preserving bounding box and generating new XML\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from lxml import etree \n",
    "import os\n",
    "import glob\n",
    "\n",
    "image_list = []\n",
    "xmin_list = []\n",
    "ymin_list = []\n",
    "ymax_list = []\n",
    "xmax_list = []\n",
    "fp1 = 'tests/cropping/*.jpg' #input filepath\n",
    "fp2 = 'tests/cropping'#bounding box info filepath\n",
    "fp3 = 'tests/cropping/output' #output folder\n",
    "\n",
    "#img1387_480.xml\n",
    "\n",
    "#Drawing the bounding box and saving      \n",
    "for file in glob.glob(fp1): \n",
    "    im=Image.open(file)\n",
    "    width, height = im.size\n",
    "    image_name, ext = os.path.splitext(file)\n",
    "    xml_filename = os.path.join(fp2, os.path.basename(image_name)+'.xml')\n",
    "    if os.path.exists(xml_filename):\n",
    "        xmin_list = []\n",
    "        ymin_list = []\n",
    "        ymax_list = []\n",
    "        xmax_list = []\n",
    "        tree = etree.parse(xml_filename)\n",
    "        root = tree.getroot()\n",
    "        xmax = root.findall('.//xmax')\n",
    "        xmin = root.findall('.//xmin')\n",
    "        ymax = root.findall('.//ymax')\n",
    "        ymin = root.findall('.//ymin')\n",
    "        \n",
    "        w = root.find('.//width')\n",
    "        h = root.find('.//height')\n",
    "\n",
    "        for idx, i in enumerate(xmax):\n",
    "            xmax_list.append(xmax[idx].text)\n",
    "            xmin_list.append(xmin[idx].text)\n",
    "            ymax_list.append(ymax[idx].text)\n",
    "            ymin_list.append(ymin[idx].text)\n",
    "        \n",
    "        # Cropping image\n",
    "        xMax = max([int(x) for x in xmax_list])\n",
    "        xMin = min([int(x) for x in xmin_list])\n",
    "        yMax = max([int(x) for x in ymax_list])\n",
    "        yMin = min([int(x) for x in ymin_list])\n",
    "        \n",
    "        if xMin >= 0 and yMin >= 0 and xMax <= width and yMax <= height: # All bounding boxes can fit in cropped image\n",
    "            left = max(0, xMin - 150)\n",
    "            top = max(0, yMin - 150)\n",
    "            right = min(xMax + 150, width)\n",
    "            bottom = min(yMax + 150, height)\n",
    "                        \n",
    "            im = im.crop((left, top, right, bottom))\n",
    "            \n",
    "            w.text = str(im.width)\n",
    "            h.text = str(im.height)\n",
    "            \n",
    "            for idx, i in enumerate(xmax_list):\n",
    "                newXmin = int(xmin_list[idx]) - left\n",
    "                newXmax = newXmin + (int(xmax_list[idx]) - int(xmin_list[idx]))\n",
    "                newYmin = int(ymin_list[idx]) - top\n",
    "                newYmax = newYmin + (int(ymax_list[idx]) - int(ymin_list[idx]))\n",
    "                \n",
    "                xmin[idx].text = str(newXmin)\n",
    "                xmax[idx].text = str(newXmax)\n",
    "                ymin[idx].text = str(newYmin)\n",
    "                ymax[idx].text = str(newYmax)\n",
    "                \n",
    "#                 #Drawing the lines\n",
    "#                 d = ImageDraw.Draw(im)\n",
    "#                 top_left = (newXmin, newYmin)\n",
    "#                 top_right = (newXmax, newYmin)\n",
    "#                 bot_left = (newXmin, newYmax)\n",
    "#                 bot_right = (newXmax, newYmax)\n",
    "#                 line_color = (0, 255, 0)\n",
    "#                 d.line([top_left, top_right, bot_right, bot_left, top_left], fill=line_color, width=2)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        #display(im)\n",
    "    else: \n",
    "        print(xml_filename + \" Doesn't exist\")\n",
    "        \n",
    "    \n",
    "    #Saving the file to a new folder\n",
    "    src_fname, ext = os.path.splitext(file)\n",
    "    save_xml = os.path.join(fp3, os.path.basename(src_fname) + '.xml')\n",
    "    save_fname = os.path.join(fp3, os.path.basename(src_fname)+'.JPEG')\n",
    "    im.save(save_fname)\n",
    "    tree.write(save_xml)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MTE482",
   "language": "python",
   "name": "mte482"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
